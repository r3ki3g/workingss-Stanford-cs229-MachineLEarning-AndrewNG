{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafb1696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:12:07.167463Z",
     "start_time": "2023-08-23T07:12:06.372654Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import HTML,Latex\n",
    "import os \n",
    "from joblib import Parallel,delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46b3f8",
   "metadata": {},
   "source": [
    "# Deep Neural Network class(scratch)\n",
    "Regularization and dropout will be implemented in next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa8b5e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:12:07.211594Z",
     "start_time": "2023-08-23T07:12:07.171471Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    def __init__(self,layers):\n",
    "        # layers :  list of dicts containing later information.\n",
    "        assert type(layers) in  (list,tuple)\n",
    "        assert len(layers) >= 2, \"At least an input and an output layer should be there\"\n",
    "        \n",
    "        # validate each layer\n",
    "        for i,layer in enumerate(layers):\n",
    "            if i==0:\n",
    "                assert layer[\"type\"] == \"input\", \"first layer should be input\"\n",
    "            elif i==len(layers)-1:\n",
    "                assert layer[\"type\"] == \"output\", \"last layer should be output\"\n",
    "            else:\n",
    "                assert layer[\"type\"] == \"hidden\", \"middle layers should be hidden\"\n",
    "                assert layer[\"activation_function\"] in (\"relu\",\"sigmoid\",\"linear\")\n",
    "                \n",
    "            assert type(layer[\"units\"]) == int\n",
    "        #done: validation\n",
    "        \n",
    "        #save these info\n",
    "        self.layers = layers\n",
    "        \n",
    "        #keep state variables\n",
    "        self.ever_trained = 0\n",
    "        \n",
    "    def absorb_parameters(self,W,B):\n",
    "        self.W=W\n",
    "        self.B=B\n",
    "        \n",
    "    def build(self,show=0):\n",
    "        # the parameters will be initialized with required dimentions\n",
    "        \n",
    "        self.W = [None] # this array will keep weight matrix  per each layer (l=1,2,..,L) ... first elem as a placeholde to indeces to work fine\n",
    "        self.B = [None] # this array will keep bias vector  per each layer (l=1,2,..,L) ... first elem as a placeholde to indeces to work fine\n",
    "        self.activation_def = [None] # the pointer to respecting activation function's definition per each layer (l=1,2,..,L) ... first elem as a placeholde to indeces to work fine\n",
    "        self.activation_derivative_def = [None] # the pointer to respecting activation function's derivative's  \n",
    "                                                                #definition per each layer (l=1,2,..,L) ... first elem as a placeholde to indeces to work fine\n",
    "        \n",
    "        self.A = [] # keep all intermidiate activation matrix per each layer (l=1,2,..,L)\n",
    "        self.Z = [] # keep all intermidiate pre-activation matrix per each layer (l=1,2,..,L)\n",
    "        \n",
    "        #initializing\n",
    "        for i in range(len(self.layers)):\n",
    "            \n",
    "            # anything for l=0,1,2,..,L ? \n",
    "            # NO\n",
    "             \n",
    "            \n",
    "            if i: #only start from layer 1,2,..,L\n",
    "                weight_matrix = np.random.randn(self.layers[i][\"units\"],self.layers[i-1][\"units\"]) * 0.01\n",
    "                bias_vector = np.zeros((self.layers[i][\"units\"],1))\n",
    "                self.W.append(weight_matrix)\n",
    "                self.B.append(bias_vector)\n",
    "                   \n",
    "               \n",
    "                self.activation_def.append(ACTIVATION_FUNC[self.layers[i][\"activation_function\"]])\n",
    "                self.activation_derivative_def.append(ACTIVATION_FUNC_DERI[self.layers[i][\"activation_function\"]])\n",
    "           \n",
    "            \n",
    "        if show: \n",
    "            print(self.W) \n",
    "            print(self.B)\n",
    "    def show_cost_history(self):\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.plot(self.cost_history)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        # these are some place holders to keep the arrays in required size\n",
    "        self.A = [None for i in range(len(self.layers))]\n",
    "        self.Z = [None for i in range(len(self.layers))]\n",
    "        self.A[0] = X # the input matrix\n",
    "        \n",
    "       \n",
    "        for i in range(1,len(self.layers)):\n",
    "                    self.Z[i] = self.W[i]@self.A[i-1]+self.B[i]\n",
    "                    self.A[i] = self.activation_def[i](self.Z[i])\n",
    "        # now all the activations in the NN are calculated and stored\n",
    "        \n",
    "        return self.A[len(self.layers) - 1]\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "    def batch_fit(self,X,Y,cost_function='least_square',n_iters=1_000,learning_rate=1e-3):\n",
    "        assert cost_function in ('least_square','binary_cross_entropy')\n",
    "        \n",
    "        ##### FWD PASS #####\n",
    "        # r3ki3g : assumes X is pre-scaled / normalized\n",
    "        \n",
    "        if not self.ever_trained:\n",
    "            # these are some place holders to keep the arrays in required size\n",
    "            self.A = [None for i in range(len(self.layers))]\n",
    "            self.Z = [None for i in range(len(self.layers))]\n",
    "\n",
    "            self.dZ = [None for i in range(len(self.layers))]\n",
    "            self.dA = [None for i in range(len(self.layers))]\n",
    "            self.dW = [None for i in range(len(self.layers))]\n",
    "            self.dB = [None for i in range(len(self.layers))]\n",
    "            \n",
    "            #update the state variable\n",
    "            self.ever_trained = 1\n",
    "        else:\n",
    "            print(\"Training again..fine tuning of parameters continued from where left at last time...\")\n",
    "\n",
    "        \n",
    "        self.A[0] = X # set the input matrix \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cost_history = []\n",
    "        start_time = time.time()\n",
    "        for iteration in range(n_iters): \n",
    "            \n",
    "                # progress message : every 100 iteration except for the first one\n",
    "                if iteration and not iteration%100:\n",
    "                        time_now = time.time()\n",
    "                        time_remaining = get_nice_time_dura_str ((n_iters - iteration) * (time_now - start_time) / iteration)\n",
    "                        print(f\"iteration : {iteration} ---> ETA : {time_remaining} \",end=\"\\r\")\n",
    "            \n",
    "            \n",
    "                ##### FWD PASS #####\n",
    "                # loop though each layer and calculate the pre-activations(Z) and activations(A)\n",
    "                for i in range(1,len(self.layers)):\n",
    "                    self.Z[i] = self.W[i]@self.A[i-1]+self.B[i]\n",
    "                    self.A[i] = self.activation_def[i](self.Z[i])\n",
    "                # now all the activations in the NN are calculated and stored\n",
    "                \n",
    "                \n",
    "                # now calculate the cost at this iteration\n",
    "                if cost_function == 'binary_cross_entropy':\n",
    "                    cost = - np.sum((Y * np.log(self.A[len(self.layers) - 1]) + (1-Y) * np.log(1 - self.A[len(self.layers) - 1]))) /  X.shape[1]\n",
    "                    #cost = np.sum((self.A[len(self.layers) - 1] - Y)**2) / X.shape[1]\n",
    "                else:\n",
    "                    raise Exception(\"not implemented yet\")\n",
    "                    \n",
    "                self.cost_history.append(cost)\n",
    "                # done : cost calc and stroing\n",
    "\n",
    "               \n",
    "\n",
    "                ##### BACK PROP #####\n",
    "                # The order l = L,L-1,L-2,...,3,2,1 (and no 0)\n",
    "                for i in range(len(self.layers) -1 , 0 , -1): # i=0 is excluded  # note :- L is at  len(self.layers) -1 index\n",
    "\n",
    "                    # dZ[L] depends on the choice of cost function\n",
    "                    if i == len(self.layers) -1:\n",
    "                                if cost_function == 'binary_cross_entropy':\n",
    "                                    self.dZ[i] = self.A[i] - Y\n",
    "                                else:\n",
    "                                    raise Exception(\"not implemented yet\")\n",
    "\n",
    "\n",
    "\n",
    "                    else: # not the last layer\n",
    "                        self.dZ[i] =  (self.W[i+1].T @ self.dZ[i+1]) * self.activation_derivative_def[i](self.Z[i])\n",
    "                    \n",
    "                    \n",
    "                    # calculate gradients\n",
    "                    m = X.shape[1]\n",
    "                    self.dW[i] = self.dZ[i]@self.A[i-1].T / m\n",
    "                    self.dB[i] = np.sum(self.dZ[i],axis=1,keepdims=1) / m\n",
    "\n",
    "                    # gradient decent\n",
    "                    self.W[i] -= learning_rate * self.dW[i]\n",
    "                    self.B[i] -= learning_rate * self.dB[i]\n",
    "\n",
    "                \n",
    "        time_now = time.time()\n",
    "        total_time = get_nice_time_dura_str(time_now - start_time)\n",
    "        print(f\"Training ended : n_iters: {n_iters} with learning_rate : {learning_rate}. Time taken : {total_time}\")\n",
    "                \n",
    "            \n",
    "        \n",
    "                      \n",
    "\n",
    "    \n",
    "    \n",
    "###### HELPER FUNCTIONS FOR DNN CLASS ###########    \n",
    "    \n",
    "# define activation functions globally\n",
    "def sigmoid(t):\n",
    "        return 1/ ( 1 + np.exp(-t) )\n",
    "      \n",
    "def relu(t): # from chat gpt : this is safe for any dimension array t\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "def relu_deri(t):\n",
    "    return np.where(t>=0,1.,0.)\n",
    "\n",
    "def sigmoid_deri(t):\n",
    "    return (1-t) * t\n",
    "\n",
    "def linear(t):\n",
    "    return t\n",
    "\n",
    "def linear_deri(t):\n",
    "    return 1\n",
    "                \n",
    "ACTIVATION_FUNC = {\"relu\":relu,\"sigmoid\":sigmoid,\"linear\":linear}\n",
    "ACTIVATION_FUNC_DERI = {\"relu\":relu_deri,\"sigmoid\":sigmoid_deri,\"linear\":linear_deri}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def get_nice_time_dura_str(time_in_secs):\n",
    "    time_in_secs = round(time_in_secs,2)\n",
    "    if time_in_secs >= 60:\n",
    "        n_mins = int(time_in_secs//60)\n",
    "        n_secs = round(time_in_secs%60,2)\n",
    "        return f\"{n_mins} min {n_secs} secs\"\n",
    "    return f\"{time_in_secs} secs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace7cdd",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7930981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:12:07.513519Z",
     "start_time": "2023-08-23T07:12:07.211594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "def get_spiral_distribution(n_points=100,noise_stats=(0,0),revolutions=1,radial_offset=0):\n",
    "    '''\n",
    "    Generate a set of (x1,x2) domain for spiral with mentioned noise stats : (mean,sigma)\n",
    "    '''\n",
    "    theta = np.random.rand(n_points) * 2 * np.pi * revolutions\n",
    "    radius = np.sqrt(theta) + radial_offset\n",
    "    mean,sigma = noise_stats\n",
    "    noise_for_radius = np.random.randn(n_points) * sigma + mean\n",
    "    radius += noise_for_radius\n",
    "    x1 = radius * np.cos(theta)\n",
    "    x2 = radius * np.sin(theta)\n",
    "    X = np.concatenate((x1.reshape(1,-1),x2.reshape(1,-1)))\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "spiral_X1 = get_spiral_distribution(revolutions=1.6,noise_stats=(0,0.1))\n",
    "spiral_X2 = get_spiral_distribution(revolutions=1.9,radial_offset=0.8,noise_stats=(0,0.1))\n",
    "\n",
    "\n",
    "#plot and see\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.scatter(spiral_X1[0,:],spiral_X1[1,:],color='green')\n",
    "ax.scatter(spiral_X2[0,:],spiral_X2[1,:],color='red')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2ea8c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-23T07:17:38.560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 37800 ---> ETA : 1 min 38.92 secs \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R3KI3G\\AppData\\Local\\Temp/ipykernel_17020/2896052004.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = - np.sum((Y * np.log(self.A[len(self.layers) - 1]) + (1-Y) * np.log(1 - self.A[len(self.layers) - 1]))) /  X.shape[1]\n",
      "C:\\Users\\R3KI3G\\AppData\\Local\\Temp/ipykernel_17020/2896052004.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = - np.sum((Y * np.log(self.A[len(self.layers) - 1]) + (1-Y) * np.log(1 - self.A[len(self.layers) - 1]))) /  X.shape[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 37900 ---> ETA : 1 min 38.93 secs \r",
      "iteration : 38000 ---> ETA : 1 min 38.94 secs \r",
      "iteration : 38100 ---> ETA : 1 min 38.9 secs \r",
      "iteration : 38200 ---> ETA : 1 min 38.88 secs \r",
      "iteration : 38300 ---> ETA : 1 min 38.89 secs \r",
      "iteration : 38400 ---> ETA : 1 min 38.93 secs \r",
      "iteration : 38500 ---> ETA : 1 min 38.94 secs \r",
      "iteration : 38600 ---> ETA : 1 min 38.9 secs \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R3KI3G\\AppData\\Local\\Temp/ipykernel_17020/2896052004.py:187: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/ ( 1 + np.exp(-t) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 147100 ---> ETA : 1 min 25.95 secs \r"
     ]
    }
   ],
   "source": [
    "# create the data set <-- combine positive and negative examples to a single array\n",
    "X_spiral_train = np.hstack((spiral_X1,spiral_X2))\n",
    "Y_spiral_train = np.hstack( ( np.ones((1,spiral_X1.shape[1])),\n",
    "                              np.zeros((1,spiral_X2.shape[1])) ))\n",
    "\n",
    "\n",
    "my_spiral_fa = DNN(layers=[\n",
    "    \n",
    "    {\n",
    "        \"type\":\"input\",\n",
    "        \"units\":2\n",
    "    },\n",
    "    \n",
    "#     {\n",
    "#         \"type\":\"hidden\",\n",
    "#         \"units\":8,\n",
    "#         \"activation_function\":\"relu\",\n",
    "#         \"regularization_strength\":1e-3,\n",
    "#         \"dropout_keep_prob\":1.0\n",
    "#     },\n",
    "    \n",
    "#     {\n",
    "#         \"type\":\"hidden\",\n",
    "#         \"units\":4,\n",
    "#         \"activation_function\":\"relu\",\n",
    "#         \"regularization_strength\":1e-3,\n",
    "#         \"dropout_keep_prob\":1.0\n",
    "#     },\n",
    "    \n",
    "    {\n",
    "        \"type\":\"hidden\",\n",
    "        \"units\":32,\n",
    "        \"activation_function\":\"relu\",\n",
    "        \"regularization_strength\":1e-3,\n",
    "        \"dropout_keep_prob\":1.0\n",
    "    },\n",
    "  \n",
    "    {\n",
    "        \"type\":\"output\",\n",
    "        \"units\":1,\n",
    "        \"activation_function\":\"sigmoid\",\n",
    "        \"regularization_strength\":1e-3,\n",
    "        \"dropout_keep_prob\":1.0\n",
    "    }\n",
    "    \n",
    "])\n",
    "\n",
    "my_spiral_fa.build()\n",
    "\n",
    "my_spiral_fa.batch_fit(X_spiral_train,\n",
    "                       Y_spiral_train,\n",
    "                       cost_function='binary_cross_entropy',\n",
    "                       n_iters=5_00_000,\n",
    "                       learning_rate=1e-1)\n",
    "\n",
    "my_spiral_fa.show_cost_history()\n",
    "\n",
    "\n",
    "\n",
    "#evaluate\n",
    "predictions = np.int32(my_spiral_fa.predict(X_spiral_train) > 0.5)\n",
    "accuracy = (predictions == Y_spiral_train).sum() / Y_spiral_train.shape[1]\n",
    "\n",
    "display(HTML(f\"<br/><font color='red' size='5'><b>Accuracy : {accuracy}</b></font>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727bb14",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6f0e3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-23T07:17:41.711Z"
    }
   },
   "outputs": [],
   "source": [
    "# from predictions clasify the training set in to positive and negatives\n",
    "pred_positives = X_spiral_train[:,predictions.reshape(-1)==1]\n",
    "pred_negatives = X_spiral_train[:,predictions.reshape(-1)!=1]\n",
    "\n",
    "#filter the wrongly identified ones\n",
    "wrong_ones = X_spiral_train[:,predictions.reshape(-1)!=Y_spiral_train.reshape(-1)]\n",
    "\n",
    "#plot and see\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,8))\n",
    "\n",
    "ax[0].scatter(spiral_X1[0,:],spiral_X1[1,:],color='green',label=\"Positives\")\n",
    "ax[0].scatter(spiral_X2[0,:],spiral_X2[1,:],color='red',label=\"Negatives\")\n",
    "ax[0].set_title(\"The training data set\")\n",
    "\n",
    "ax[1].scatter(pred_positives[0,:],pred_positives[1,:],color='green',label=\"Positives\")\n",
    "ax[1].scatter(pred_negatives[0,:],pred_negatives[1,:],color='red',label=\"Negatives\")\n",
    "ax[1].set_title(\"Predicted after training\")\n",
    "\n",
    "ax[1].scatter(wrong_ones[0,:],wrong_ones[1,:],facecolors='none', edgecolors='brown', s=300,label=\"wrongly predicted\")\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12effea",
   "metadata": {},
   "source": [
    "## Development (finding a good set of hyper parameters)\n",
    "The next cell will be frozen to avoid starting the process by accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c63ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T13:31:01.568400Z",
     "start_time": "2023-08-21T13:31:01.556377Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_dev_test(h1,h2,h3):\n",
    "        my_spiral_fa = DNN(layers=[\n",
    "\n",
    "            {\n",
    "                \"type\":\"input\",\n",
    "                \"units\":2\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"hidden\",\n",
    "                \"units\":h1,\n",
    "                \"activation_function\":\"relu\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"hidden\",\n",
    "                \"units\":h2,\n",
    "                \"activation_function\":\"relu\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"hidden\",\n",
    "                \"units\":h3,\n",
    "                \"activation_function\":\"relu\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"output\",\n",
    "                \"units\":1,\n",
    "                \"activation_function\":\"sigmoid\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            }\n",
    "\n",
    "        ])\n",
    "\n",
    "        my_spiral_fa.build()\n",
    "\n",
    "        my_spiral_fa.batch_fit(X_spiral_train,\n",
    "                               Y_spiral_train,\n",
    "                               cost_function='binary_cross_entropy',\n",
    "                               n_iters=4_00_000,\n",
    "                               learning_rate=1e-3)\n",
    "\n",
    "        my_spiral_fa.show_cost_history()\n",
    "        final_cost_history = my_spiral_fa.cost_history\n",
    "        \n",
    "        return (h1,h2,h3),final_cost_history,my_spiral_fa.W,my_spiral_fa.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1023fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:13:45.351366Z",
     "start_time": "2023-08-23T07:13:45.093836Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_dev_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17020/3578167984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m task_set = [delayed(full_dev_test)(h1,h2,h3) for h1 in [2,4,8,16,32,64]\n\u001b[0m\u001b[0;32m      2\u001b[0m                                               \u001b[1;32mfor\u001b[0m \u001b[0mh2\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                for h3 in [8,16,32,64]]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total tasks\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17020/3578167984.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m task_set = [delayed(full_dev_test)(h1,h2,h3) for h1 in [2,4,8,16,32,64]\n\u001b[0m\u001b[0;32m      2\u001b[0m                                               \u001b[1;32mfor\u001b[0m \u001b[0mh2\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                for h3 in [8,16,32,64]]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total tasks\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_dev_test' is not defined"
     ]
    }
   ],
   "source": [
    "task_set = [delayed(full_dev_test)(h1,h2,h3) for h1 in [2,4,8,16,32,64]\n",
    "                                              for h2 in [8,16,32,64,128]\n",
    "                                               for h3 in [8,16,32,64]]\n",
    "\n",
    "print(\"total tasks\", len(task_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ba44d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:13:45.351366Z",
     "start_time": "2023-08-23T07:13:45.351366Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#results = Parallel(n_jobs=7)(task_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c30d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:13:45.355387Z",
     "start_time": "2023-08-23T07:13:45.355387Z"
    }
   },
   "outputs": [],
   "source": [
    "final_costs = [final_cost_history[-1] for (h1,h2,h3),final_cost_history,_,_ in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5665d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:13:45.355387Z",
     "start_time": "2023-08-23T07:13:45.355387Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.argmin(final_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a77684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T17:04:18.441242Z",
     "start_time": "2023-08-21T17:04:18.391140Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f0a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:13:45.359369Z",
     "start_time": "2023-08-23T07:13:45.359369Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test with that (119 th network)\n",
    "(h1,h2,h3),final_cost_history,W,B = results[1]\n",
    "\n",
    "my_spiral_fa_ = DNN(layers=[\n",
    "\n",
    "            {\n",
    "                \"type\":\"input\",\n",
    "                \"units\":2\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"hidden\",\n",
    "                \"units\":h1,\n",
    "                \"activation_function\":\"relu\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"hidden\",\n",
    "                \"units\":h2,\n",
    "                \"activation_function\":\"relu\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"hidden\",\n",
    "                \"units\":h3,\n",
    "                \"activation_function\":\"relu\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"type\":\"output\",\n",
    "                \"units\":1,\n",
    "                \"activation_function\":\"sigmoid\",\n",
    "                \"regularization_strength\":1e-3,\n",
    "                \"dropout_keep_prob\":1.0\n",
    "            }\n",
    "\n",
    "        ])\n",
    "\n",
    "my_spiral_fa_.build()\n",
    "my_spiral_fa_.absorb_parameters(W,B)\n",
    "\n",
    "\n",
    "predictions = np.int32(my_spiral_fa_.predict(X_spiral_train) > 0.5)\n",
    "accuracy = (predictions == Y_spiral_train).sum() / Y_spiral_train.shape[1]\n",
    "\n",
    "display(HTML(f\"<br/><font color='red' size='5'><b>Accuracy : {accuracy*100}%</b></font>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05feb403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:13:45.359369Z",
     "start_time": "2023-08-23T07:13:45.359369Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "serealizable_results = []\n",
    "\n",
    "for (h1,h2,h3),final_cost_history,W,B in results:\n",
    "    W_ =[]\n",
    "    for w in W:\n",
    "        if isinstance(w,np.ndarray):\n",
    "            w=w.tolist()\n",
    "        W_.append(w)\n",
    "    B_ = []\n",
    "    for b in B:\n",
    "        if isinstance(b,np.ndarray):\n",
    "            b=b.tolist()\n",
    "        B_.append(b)\n",
    "    \n",
    "    serealizable_results.append(((h1,h2,h3),final_cost_history,W_,B_))\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "basepath =  r'D:\\ENTC\\PROJECTS\\machine-learning-andrew-ng\\workingss-Stanford-cs229-MachineLearning+Coursera-ML-Specialization-AndrewNG\\resources\\\\'\n",
    "with open(basepath + 'parameters_1.json','w') as file:\n",
    "    json.dump(serealizable_results,file)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
